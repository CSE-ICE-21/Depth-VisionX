{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import required Libraries\n",
    "\n",
    "* Numpy for calculations\n",
    "* OpenCV for image processing, image reading and image writting\n",
    "* Matplotlib for Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing images for Stereo Vision and initialize disparity limit and block length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disparities = 64\n",
    "block = 15\n",
    "\n",
    "left = cv.imread('../images/image_4_l.png', cv.IMREAD_GRAYSCALE)\n",
    "right = cv.imread('../images/image_4_r.png', cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "disparity = np.zeros(shape=(left.shape[0]-(block-1), left.shape[1]-(block-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLock Matching Algorithms\n",
    "\n",
    "Local methods compute disparity by considering a small neighborhood (window) around each pixel in one image and searching for the corresponding block in the other image. These methods are computationally efficient and typically used for real-time applications.\n",
    "\n",
    "- SAD Algorithm\n",
    "- SSD Algorithm\n",
    "- Normalized Cross Correlation\n",
    "- Census Transform\n",
    "\n",
    "# Global Methods\n",
    "\n",
    "Global methods solve the stereo matching problem by optimizing a global energy function. These methods aim to produce a smooth disparity map that is globally consistent across the entire image. However, they tend to be more computationally expensive compared to local methods.\n",
    "\n",
    "- Graph Cuts\n",
    "- Dynamic Programming Methods\n",
    "- Semi Global Methods\n",
    "\n",
    "# Hybrid Methods\n",
    "\n",
    "Hybrid methods combine elements of both local and global approaches, attempting to leverage the advantages of both. \n",
    "\n",
    "# Neural Networks\n",
    "\n",
    "With the rise of deep learning, there has been increasing interest in using convolutional neural networks (CNNs) and other machine learning techniques to improve stereo vision algorithms. These methods learn to predict disparities from large datasets of stereo images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAD Algorithm for disparity Maps\n",
    "\n",
    "The Sum of Absolute Differences (SAD) algorithm is one of the most widely used techniques for block-based stereo matching in computer vision, particularly for depth map creation. It compares blocks of pixels (also known as windows) between the left and right images to compute disparity, which is the pixel shift between the two images caused by the depth of objects in the scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(left.shape[0] - block):\n",
    "    print(i, \"Running ...\")\n",
    "    for j in range(left.shape[1] - block):\n",
    "        ssd = []\n",
    " \n",
    "        l = left[(i) : (i + block), (j) : (j + block)]\n",
    "        \n",
    "        for d in range(0, disparities):\n",
    "            if d + j + block >= right.shape[1]:\n",
    "                break\n",
    "            r = right[(i) : (i + block), (j + d) : (j + d + block)]\n",
    "            try:\n",
    "                ssd.append(np.sum((l[:,:]-r[:,:])))\n",
    "            except:\n",
    "                print(\"r : \" , r.shape)\n",
    "                print(\"l : \", l.shape)\n",
    "        disparity[i, j] = np.argmin(ssd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSD Algorithm for disparity maps\n",
    "\n",
    "The Sum of Squared Differences (SSD) algorithm is used in stereo vision for computing the disparity between two images (usually from a stereo camera pair). Like other block-matching algorithms, SSD compares small blocks of pixels from one image (typically the left image) to corresponding blocks in the other image (typically the right image). It measures the difference between blocks using the squared differences of pixel intensities and is often used for estimating depth in stereo vision systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(left.shape[0] - block):\n",
    "    print(i, \"Running ...\")\n",
    "    for j in range(left.shape[1] - block):\n",
    "        ssd = []\n",
    " \n",
    "        l = left[(i) : (i + block), (j) : (j + block)]\n",
    "        \n",
    "        for d in range(0, disparities):\n",
    "            if d + j + block >= right.shape[1]:\n",
    "                break\n",
    "            r = right[(i) : (i + block), (j + d) : (j + d + block)]\n",
    "            try:\n",
    "                ssd.append(np.sum((l[:,:]-r[:,:])) ** 2)\n",
    "            except:\n",
    "                print(\"r : \" , r.shape)\n",
    "                print(\"l : \", l.shape)\n",
    "        disparity[i, j] = np.argmin(ssd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalized Cross-Correlation (NCC)\n",
    "\n",
    "This is a block-matching algorithm often used in stereo vision and template matching. It evaluates how similar two blocks (or windows) of pixels are by normalizing the pixel values, making it more robust to changes in lighting and contrast. Unlike SAD or SSD, which compare pixel values directly, NCC compares the relative patterns of intensity between corresponding blocks, leading to better performance in cases where images may have different brightness or contrast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disparity = np.zeros((left.shape[0], left.shape[1]), dtype=np.float32)\n",
    "\n",
    "half_block = block // 2\n",
    "\n",
    "for i in range(half_block, left.shape[0] - half_block):\n",
    "    for j in range(half_block, left.shape[1] - half_block):\n",
    "        \n",
    "        left_block = left[i - half_block:i + half_block + 1, j - half_block:j + half_block + 1]\n",
    "        mean_left = np.mean(left_block)\n",
    "        \n",
    "        normalized_left = left_block - mean_left\n",
    "        \n",
    "        best_ncc = -1\n",
    "        best_disparity = 0\n",
    "        \n",
    "        for d in range(disparities):\n",
    "            if j - d - half_block >= 0:\n",
    "                right_block = right[i - half_block:i + half_block + 1, j - d - half_block:j - d + half_block + 1]\n",
    "                mean_right = np.mean(right_block)\n",
    "                \n",
    "                normalized_right = right_block - mean_right\n",
    "                \n",
    "                numerator = np.sum(normalized_left * normalized_right)\n",
    "                \n",
    "                denominator = np.sqrt(np.sum(normalized_left ** 2) * np.sum(normalized_right ** 2))\n",
    "                \n",
    "                if denominator > 0:\n",
    "                    ncc_value = numerator / denominator\n",
    "                    \n",
    "                    if ncc_value > best_ncc:\n",
    "                        best_ncc = ncc_value\n",
    "                        best_disparity = d\n",
    "        \n",
    "        disparity[i, j] = best_disparity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Census ALgorithm\n",
    "\n",
    " This is a method used in stereo vision for disparity estimation. It encodes local intensity information of an image into a binary representation, providing robustness against illumination changes, noise, and other variations. This makes it a popular choice for disparity estimation in various computer vision tasks, including depth mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def census_transform(image, window_size):\n",
    "    height, width = image.shape\n",
    "    half_window = window_size // 2\n",
    "    census_image = np.zeros((height, width), dtype=np.uint32)\n",
    "\n",
    "    for i in range(half_window, height - half_window):\n",
    "        for j in range(half_window, width - half_window):\n",
    "            center_pixel = image[i, j]\n",
    "            binary_pattern = 0\n",
    "            \n",
    "            for m in range(-half_window, half_window + 1):\n",
    "                for n in range(-half_window, half_window + 1):\n",
    "                    if not (m == 0 and n == 0):\n",
    "                        neighbor_pixel = image[i + m, j + n]\n",
    "                        binary_pattern <<= 1\n",
    "                        if neighbor_pixel < center_pixel:\n",
    "                            binary_pattern |= 1\n",
    "            \n",
    "            census_image[i, j] = binary_pattern\n",
    "\n",
    "    return census_image\n",
    "\n",
    "left_census = census_transform(left, block)\n",
    "right_census = census_transform(right, )\n",
    "\n",
    "height, width = left.shape\n",
    "disparity = np.zeros((height, width), dtype=np.float32)\n",
    "\n",
    "for i in range(height):\n",
    "    for j in range(width):\n",
    "        min_hamming_distance = float('inf')\n",
    "        best_disparity = 0\n",
    "\n",
    "        for d in range(disparities):\n",
    "            if j - d >= 0: \n",
    "                hamming_dist = np.bitwise_xor(left_census[i, j], right_census[i, j - d]).sum()\n",
    "                if hamming_dist < min_hamming_distance:\n",
    "                    min_hamming_distance = hamming_dist\n",
    "                    best_disparity = d\n",
    "\n",
    "        disparity[i, j] = best_disparity"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
